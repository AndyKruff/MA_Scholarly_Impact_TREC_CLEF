{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea74137f-a6f6-4e99-866a-9307517a07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80764863-097d-4f2a-80c6-c47a2c3e796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trec = pd.read_parquet(\"../../../data/metadata_TREC.parquet\")\n",
    "df_ceur = pd.read_parquet(\"../../../data/metadata_CEUR.parquet\")\n",
    "df_lncs = pd.read_parquet(\"../../../data/metadata_LNCS.parquet\")\n",
    "df_lncs.loc[df_lncs['ID'] == \"lncs_649\", 'Section'] = \"CLEF at SemEval 2007\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b395715a-eccd-4e13-b4b8-0cdb5729c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Influential Citation Counts to the proceeding paper metadata\n",
    "\n",
    "def add_SemanticCitations(df, path):\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        SemanticCitations = json.load(file)\n",
    "    \n",
    "    citations_semantic = []\n",
    "    for i in SemanticCitations:\n",
    "        try:\n",
    "            citations_semantic.append([i, SemanticCitations[i][\"influentialCitationCount\"]])\n",
    "        except:\n",
    "            print(i)\n",
    "    df_citations = pd.DataFrame(citations_semantic, columns=[\"ID\", \"Citations_semantic\"])\n",
    "    merge = pd.merge(df, df_citations, how=\"left\" , left_on = \"ID\", right_on=\"ID\")\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b43ead-2a46-45d8-bef3-fa0f1cda5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lncs = add_SemanticCitations(df_lncs, \"../../../data/SemanticScholar_LNCS_additional_metadata.json\")\n",
    "df_trec = add_SemanticCitations(df_trec, \"../../../data/SemanticScholar_TREC_additional_metadata.json\")\n",
    "df_ceur = add_SemanticCitations(df_ceur, \"../../../data/SemanticScholar_CEUR_additional_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c37bb58-5625-4d45-ae61-8e75fc48d2e5",
   "metadata": {},
   "source": [
    "df_lncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f07138a-8b44-4143-9907-3651a6b58094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lncs = df_lncs[['Title', 'Citations_semantic']].sort_values(by='Citations_semantic', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f76211c-37c1-4f53-9f2a-a809ea368048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Citations_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>The Philosophy of Information Retrieval Evalua...</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>A Test Collection for Research on Depression a...</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>Overview of RepLab 2013: Evaluating Online Rep...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>CLEF-IP 2009: Retrieval Experiments in the Int...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>Overview of eRisk: Early Risk Prediction on th...</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Overview of the ShARe/CLEF eHealth Evaluation ...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>Modeling of the Question Answering Task in the...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Overview of the ImageCLEFphoto 2008 Photograph...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>Overview of eRisk 2021: Early Risk Prediction ...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Improving the Reproducibility of PAN’s Shared ...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  Citations_semantic\n",
       "421   The Philosophy of Information Retrieval Evalua...                35.0\n",
       "361   A Test Collection for Research on Depression a...                32.0\n",
       "1223  Overview of RepLab 2013: Evaluating Online Rep...                23.0\n",
       "633   CLEF-IP 2009: Retrieval Experiments in the Int...                19.0\n",
       "1058  Overview of eRisk: Early Risk Prediction on th...                19.0\n",
       "1021  Overview of the ShARe/CLEF eHealth Evaluation ...                18.0\n",
       "941   Modeling of the Question Answering Task in the...                18.0\n",
       "727   Overview of the ImageCLEFphoto 2008 Photograph...                16.0\n",
       "1108  Overview of eRisk 2021: Early Risk Prediction ...                16.0\n",
       "1026  Improving the Reproducibility of PAN’s Shared ...                15.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lncs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b828f8-b4ac-41f4-954e-8a38a2301d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Philosophy of Information Retrieval Evaluation\n",
      "A Test Collection for Research on Depression and Language Use\n",
      "Overview of RepLab 2013: Evaluating Online Reputation Monitoring Systems\n",
      "CLEF-IP 2009: Retrieval Experiments in the Intellectual Property Domain\n",
      "Overview of eRisk: Early Risk Prediction on the Internet\n",
      "Overview of the ShARe/CLEF eHealth Evaluation Lab 2014\n",
      "Modeling of the Question Answering Task in the YodaQA System\n",
      "Overview of the ImageCLEFphoto 2008 Photographic Retrieval Task\n",
      "Overview of eRisk 2021: Early Risk Prediction on the Internet\n",
      "Improving the Reproducibility of PAN’s Shared Tasks:\n"
     ]
    }
   ],
   "source": [
    "for i in df_lncs[\"Title\"].head(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a81329b-f9ce-4cf3-9016-7dc6f4ed304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ceur = df_ceur[['Title', 'Citations_semantic']].sort_values(by='Citations_semantic', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c85da8-591f-4cf0-b505-ac659d3016eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of the 3rd Author Profiling Task at PAN 2015\n",
      "Author Identification Using Multi-headed Recurrent Neural Networks\n",
      "VQA-Med: Overview of the Medical Visual Question Answering Task at ImageCLEF 2019\n",
      "Overview of the International Sexual Predator Identification Competition at PAN-2012\n",
      "Overview of the 5th Author Profiling Task at PAN 2017: Gender and Language Variety Identification in Twitter\n",
      "Overview of the 8th Author Profiling Task at PAN 2020: Profiling Fake News Spreaders on Twitter\n",
      "Overview of eRisk: Early Risk Prediction on the Internet (Extended Lab Overview)\n",
      "CLEF-IP 2009: Retrieval Experiments in the Intellectual Property Domain\n",
      "Fine-tuning Deep Convolutional Networks for Plant Recognition\n",
      "Question Answering over Linked Data (QALD-4)\n"
     ]
    }
   ],
   "source": [
    "for i in df_ceur[\"Title\"].head(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35842e18-4f56-4eee-88a4-79ba595c9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trec = df_trec[['Title', 'Citations_semantic']].sort_values(by='Citations_semantic', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8351c9a-7bb0-4715-9aea-b7d462deab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMass at TREC 2004: Novelty and HARD.\n",
      "Overview of the TREC 2003 Question Answering Track.\n",
      "Overview of the TREC 2019 Deep Learning Track\n",
      "Overview of the TREC 2009 Web Track.\n",
      "TREC 2007 Genomics Track Overview.\n",
      "Overview of the TREC 2020 Deep Learning Track.\n",
      "Overview of the TREC 2011 Microblog Track.\n",
      "Overview of the TREC 2014 Clinical Decision Support Track.\n",
      "Overview of the TREC 2006 Blog Track.\n",
      "The TREC 2002 Filtering Track Report.\n"
     ]
    }
   ],
   "source": [
    "for i in df_trec[\"Title\"].head(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f50944-c459-4c2a-90fa-fc3a92fbf1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MasterThesisEnv)",
   "language": "python",
   "name": "masterthesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
