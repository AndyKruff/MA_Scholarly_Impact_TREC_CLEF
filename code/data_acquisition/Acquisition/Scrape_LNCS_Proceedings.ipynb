{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81936f35-4e38-4da7-8c96-137c00e9a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7f73a-3847-4a48-b1fa-1f4a33771509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where the PDF files will be saved\n",
    "path = 'D:/Studium/Masterarbeit/PythonProject/data/PDF_data/'\n",
    "\n",
    "# Open the file containing the list of links to CLEF proceedings and read all links into a list\n",
    "with open(\"D:/Studium/Masterarbeit/PythonProject/data/links.txt\") as file:\n",
    "    publisher_link_list_doi_new = [line.rstrip() for line in file]\n",
    "\n",
    "\n",
    "for i in publisher_link_list_doi_new[10:13]:\n",
    "    resp = requests.get(i)\n",
    "    \n",
    "    # Extract the book name from the page and clean it up\n",
    "    soup_book_name = BeautifulSoup(resp.text, features=\"html.parser\").find(\"p\", attrs={\"data-test\" : \"book-subtitle\"})\n",
    "    book_name = soup_book_name.text.split(\",\")[0]\n",
    "\n",
    "    # Try to create a directory for the book; ignore error if the directory already exists\n",
    "    try:\n",
    "        os.mkdir(path + \"LNCS_Proceedings/\" + book_name)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # Find the section of the page that contains the table of contents\n",
    "    soup = BeautifulSoup(resp.text, features=\"html.parser\").find(\"section\", attrs={\"data-title\" : \"Table of contents\"})\n",
    "    \n",
    "    # Get all the chapter headings and the lists of publications under each heading\n",
    "    headings = soup.findAll(\"h3\", attrs={\"class\" : \"c-book-part-heading--underline\"})\n",
    "    lists_of_publications = soup.findAll(\"ol\", attrs={\"class\": \"u-list-reset\"})\n",
    "\n",
    "    # Iterate over each chapter and its corresponding list of publications\n",
    "    for j in range(len(headings)):\n",
    "        try:\n",
    "            # Clean the chapter name by removing invalid characters\n",
    "            chapter_name = headings[j].text.replace(\":\", \"\")\n",
    "            chapter_name = chapter_name.replace(\"?\", \"\")\n",
    "            \n",
    "            # Try to create a directory for the chapter; ignore error if it already exists\n",
    "            os.mkdir(path + \"LNCS_Proceedings/\" + book_name + \"/\" + chapter_name)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Find all links to individual publications within the chapter\n",
    "        chapter_publication_links = lists_of_publications[j].findAll(\"a\",attrs={\"data-track-action\" : \"ToC link to content page\"})\n",
    "        \n",
    "        # Iterate over each publication link\n",
    "        for k in chapter_publication_links:\n",
    "            # Extract the DOI part from the link using regex\n",
    "            doi_suffix = re.search(r'/chapter/10.1007/(.+?)(?:/|$)', k.get(\"href\")).group(1)\n",
    "            \n",
    "            # Clean the title by removing or replacing invalid characters\n",
    "            title = k.text.replace(\"?\",\"\")\n",
    "            title = title.replace(\"<i>\",\"\").replace(\"</i>\", \"\")\n",
    "            \n",
    "            # Construct the full filename for saving the PDF, and ensure the path is not too long\n",
    "            filename = path + \"LNCS_Proceedings/\" + book_name + \"/\" + chapter_name + \"/\" + title + \".pdf\"\n",
    "            if len(filename) > 260:\n",
    "                diff = len(filename) - 264\n",
    "                filename = filename[:-diff] + \".pdf\"\n",
    "            \n",
    "            # Download the PDF file from the constructed URL and save it to the appropriate location\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(requests.get(urljoin(\"https://link.springer.com/content/pdf/10.1007/\", doi_suffix)).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "113ff551-28ff-496c-bc36-32423c69b0d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1 else, except\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-031-04431-1\n",
      "https://doi.org/10.1007/978-3-642-23008-0\n",
      "https://doi.org/10.1007/978-3-642-23008-0 else, except\n",
      "https://doi.org/10.1007/978-3-642-23008-0\n",
      "https://doi.org/10.1007/978-3-642-23008-0 else, except\n",
      "https://doi.org/10.1007/978-3-642-23008-0\n",
      "https://doi.org/10.1007/978-3-642-23008-0 else, except\n",
      "https://doi.org/10.1007/978-3-642-23008-0\n",
      "https://doi.org/10.1007/978-3-642-23008-0 else, except\n",
      "https://doi.org/10.1007/978-3-642-23008-0\n",
      "https://doi.org/10.1007/978-3-642-23008-0 else, except\n",
      "https://doi.org/10.1007/978-3-642-23008-0\n",
      "https://doi.org/10.1007/978-3-642-23008-0 else, except\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-030-22948-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=1#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n",
      "https://link.springer.com/book/10.1007/978-3-642-15181-1?page=2#toc\n"
     ]
    }
   ],
   "source": [
    "documents_data = []\n",
    "\n",
    "# Open the file containing the list of links to CLEF proceedings and read all links into a list\n",
    "with open(\"D:/Studium/Masterarbeit/PythonProject/data/links.txt\") as file:\n",
    "    publisher_link_list_doi_new = [line.rstrip() for line in file]\n",
    "    \n",
    "# Iterate over each link in the list\n",
    "for i in publisher_link_list_doi_new:\n",
    "    # Send a GET request to the URL and parse the HTML response\n",
    "    resp = requests.get(i)\n",
    "    \n",
    "    # Extract the book subtitle and title\n",
    "    soup_book_name = BeautifulSoup(resp.text, features=\"html.parser\").find(\"p\", attrs={\"data-test\" : \"book-subtitle\"})\n",
    "    soup_book_title = BeautifulSoup(resp.text, features=\"html.parser\").find(\"h1\", attrs={\"data-test\" : \"book-title\"})\n",
    "    book_name = soup_book_name.text.split(\",\")[0]\n",
    "    \n",
    "    # Adjust the book name if it ends with \"Part I\" or \"Part II\"\n",
    "    if soup_book_name.text.strip().endswith(\"Part I\") or soup_book_name.text.strip().endswith(\"Part II\"): \n",
    "        book_name += \" (\" + soup_book_name.text.split(\",\")[-1].strip() + \")\"\n",
    "\n",
    "    # Extract the publication year from the page\n",
    "    soup_book_name = BeautifulSoup(resp.text, features=\"html.parser\").findAll(\"li\", attrs={\"class\" : \"c-article-identifiers__item\"})\n",
    "    year = soup_book_name[1].text.replace(\"© \", \"\")\n",
    "    \n",
    "    # Find all chapter links in the book\n",
    "    soup = BeautifulSoup(resp.text, features=\"html.parser\").findAll(\"a\", attrs={\"href\" : re.compile(\"/chapter/10.1007/\")})\n",
    "    \n",
    "    # Iterate over each chapter link found\n",
    "    for j in soup:\n",
    "        document_info = []\n",
    "        try:\n",
    "            # Add the year, book name, and book title to the list for this document\n",
    "            document_info.extend([year.group(), book_name, soup_book_title.text.rstrip().lstrip()])\n",
    "        except:\n",
    "            # Handle case where year is not found\n",
    "            document_info.extend([\"Not found\", book_name, soup_book_title.text.rstrip().lstrip()])\n",
    "        \n",
    "        # Extract the href attribute and modify it to form the PDF file name\n",
    "        href = j.get(\"href\")\n",
    "        href_2 = re.sub(\"/chapter/10.1007/\", \"\",  href) + \".pdf\"\n",
    "        document_info.append(href_2)\n",
    "\n",
    "        # Find the previous h3 (chapter title) and h4 (sub-chapter title) elements\n",
    "        previous_h3 = j.find_previous(\"h3\", attrs={\"data-title\" : \"part-title\"})\n",
    "        \n",
    "        # Check if there is an h4 element (sub-chapter title)\n",
    "        if j.find_previous(\"h4\", attrs={\"data-title\" : \"subpart-title\"}):\n",
    "            previous_h4 = j.find_previous(\"h4\", attrs={\"data-title\" : \"subpart-title\"})\n",
    "            try:\n",
    "                # Add the chapter title, part title, and sub-part title to the list\n",
    "                document_info.extend([j.text, previous_h3.text, previous_h4.text])\n",
    "            except:\n",
    "                # Handle case where part title is not found\n",
    "                document_info.extend([j.text, \"Not found\", previous_h4.text])\n",
    "        else:\n",
    "            try:\n",
    "                # Add the chapter title and part title, with \"Uncategorized\" as sub-part title\n",
    "                document_info.extend([j.text, previous_h3.text, \"Uncategorized\"])\n",
    "            except:\n",
    "                # Handle case where part title is not found\n",
    "                document_info.extend([j.text, \"Not found\", \"Uncategorized\"])\n",
    "        \n",
    "        # Send a request to the chapter page to extract additional information\n",
    "        resp = requests.get(\"https://link.springer.com\" + href)\n",
    "\n",
    "        # Extract the authors and affiliations\n",
    "        authors_affiliations = BeautifulSoup(resp.text, features=\"html.parser\").find(\"ol\", attrs={\"class\" : \"c-article-author-affiliation__list\"})\n",
    "\n",
    "        # Extract the DOI and citation count\n",
    "        doi_soup = BeautifulSoup(resp.text, features=\"html.parser\").findAll(\"span\", attrs={\"class\" : \"c-bibliographic-information__value\"})\n",
    "        try:\n",
    "            citation_soup = BeautifulSoup(resp.text, features=\"html.parser\").findAll(\"li\", attrs={\"class\":\"app-article-metrics-bar__item\"})\n",
    "            document_info.extend([doi_soup[0].text, re.sub(\"Citations\", \"\", citation_soup[1].text).lstrip().rstrip()])\n",
    "        except:\n",
    "            # Handle case where citation count is not found\n",
    "            document_info.extend([doi_soup[0].text, \"Not found\"])\n",
    "        \n",
    "        # Extract the list of authors and their affiliations\n",
    "        authors_affiliations_list = []\n",
    "        for li in authors_affiliations.find_all('li'):\n",
    "            author_info = []\n",
    "            # Iterate through all p elements within the li element (author name and affiliation)\n",
    "            for p in li.find_all('p'):\n",
    "                if len(author_info) == 0:\n",
    "                    # Add the author's name to the list\n",
    "                    author_info.append(p.text)\n",
    "                else:\n",
    "                    # Split the affiliations and add them to the list\n",
    "                    author_info.append(re.split(r'\\s&\\s|,\\s', p.text))\n",
    "                \n",
    "            authors_affiliations_list.append(author_info)\n",
    "        # Add the authors and affiliations to the list for this document\n",
    "        documents_data.append(authors_affiliations_list)\n",
    "        \n",
    "        # Add the complete document information to the main list\n",
    "        documents_data.append(document_info)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d05efbc7-d5f7-4d0c-9db9-8b1670dd7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"PubYear\", \"Book Subtitle\", \"Book Title\", \"Filename\", \"Title\", \"Section\", \"Subsection\", \"DOI\", \"Citation count\", \"Authors & Affiliations\"]\n",
    "publication_metadata_df = pd.DataFrame(documents_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "575b14d3-2749-449e-93a1-1116515b49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_metadata_df.to_parquet(\"../../../data/metadata_LNCS.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MasterThesisEnv)",
   "language": "python",
   "name": "masterthesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
